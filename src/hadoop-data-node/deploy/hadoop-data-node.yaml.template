# Copyright (c) Microsoft Corporation
# All rights reserved.
#
# MIT License
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
# to permit persons to whom the Software is furnished to do so, subject to the following conditions:
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
# BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

{% set folders = cluster_cfg[ "hadoop-data-node" ][ "storage_path" ] or cluster_cfg["cluster"]["common"][ "data-path" ] + "/hdfs/data" %}
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: hadoop-data-node-ds
spec:
  selector:
    matchLabels:
      app: hadoop-data-node
  template:
    metadata:
      labels:
        app: hadoop-data-node
    spec:
      hostNetwork: true
      hostPID: false
      containers:
      - name:  hadoop-data-node
        image: {{ cluster_cfg["cluster"]["docker-registry"]["prefix"] }}hadoop-run:{{ cluster_cfg["cluster"]["docker-registry"]["tag"] }}
        imagePullPolicy: Always
        volumeMounts:
        {% set mount_points = [] %}
        {% for folder in folders.split(",") %}
        - mountPath: /var/lib/hdfs/data-{{ loop.index }}
          name: hadoop-data-storage-{{ loop.index }}
          {% set ignored = mount_points.append("file:///var/lib/hdfs/data-" + loop.index|string) %}
        {% endfor %}
        - mountPath: /hadoop-configuration
          name: hadoop-data-node-config-volume
        - mountPath: /host-configuration
          name: host-confg-volume
        - mountPath: /var/lib/hadoopdata
          name: hadoop-tmp-storage
        - mountPath: /var/log/hadoop
          name: log-dir
        readinessProbe:
          exec:
            command:
            - cat
            - /jobstatus/jobok
          initialDelaySeconds: 5
          periodSeconds: 3
        {%- if cluster_cfg['cluster']['common']['qos-switch'] == "true" %}
        resources:
          limits:
            memory: "4Gi"
          requests:
            memory: "1Gi"
        {%- endif %}
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: HADOOP_DATANODE_OPTS
          value: "-Xmx2048m"
        - name: HDFS_ADDRESS
          value: {{ cluster_cfg[ "hadoop-name-node" ][ "master-ip" ] }}
        - name: GENERATE_CONFIG
          value: datanode-generate-script.sh
        - name: START_SERVICE
          value: datanode-start-service.sh
        - name: HADOOP_DATANODE_DATA_DIR
          value: {{ mount_points|join(",") }}
        # Rolling File Appender, by default it keeps at most 256M*20=5G logs.
        - name: HADOOP_ROOT_LOGGER
          value: INFO,console,RFA
        - name: HADOOP_LOG_DIR
          value: /var/log/hadoop
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
      imagePullSecrets:
      - name: {{ cluster_cfg["cluster"]["docker-registry"]["secret-name"] }}
      volumes:
      - name: hadoop-tmp-storage
        hostPath:
          path: {{ cluster_cfg["cluster"]["common"][ "data-path" ] }}/hadooptmp/datanode
      {% for folder in folders.split(",") %}
      - name: hadoop-data-storage-{{ loop.index }}
        hostPath:
          path: {{ folder }}
      {% endfor %}
      - name: hadoop-data-node-config-volume
        configMap:
          name:  hadoop-data-node-configuration
      - name: host-confg-volume
        configMap:
          name: host-configuration
      - name: log-dir
        hostPath:
          path: {{ cluster_cfg["cluster"]["common"][ "data-path" ] }}/pai-service-log/data-node
      tolerations:
      - key: node.kubernetes.io/memory-pressure
        operator: "Exists"
      - key: node.kubernetes.io/disk-pressure
        operator: "Exists"
      - key: node.kubernetes.io/out-of-disk
        operator: "Exists"
