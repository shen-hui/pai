# PAI Job Exit Spec
1. See details in [job-exit-spec.yaml](job-exit-spec.yaml)
2. This markdown file is generated by [update_markdown.py](update_markdown.py) with [job-exit-spec.yaml](job-exit-spec.yaml)
3. See full doc in [PAI Job Exit Spec User Manual](user-manual.md)

## Spec Schema
|field|description|required|unique|type|range|
|-----|-----------|--------|------|----|----|
| **code** | The PAI Job ExitCode | True | True | Integer | begin: -8000<br>end: 256<br> |
| **phrase** | The textual phrase representation of this ExitCode | True | True | String | Any |
| **issuer** | Who root issued this ExitCode in details | False | False | Enum | 1. USER_CONTAINER<br>2. PAI_OS<br>3. PAI_RUNTIME<br>4. PAI_YARN<br>5. PAI_LAUNCHER<br> |
| **causer** | Who root caused this ExitCode in details | False | False | Enum | 1. USER_SUBMISSION<br>2. USER_CONTAINER<br>3. USER_STOP<br>4. USER_DELETION<br>5. USER_RETRY<br>6. USER_UPGRADE<br>7. RESOURCE_ALLOCATION_TIMEOUT<br>8. PAI_HDFS<br>9. PAI_OS<br>10. PAI_DOCKER<br>11. PAI_RUNTIME<br>12. PAI_YARN<br>13. PAI_LAUNCHER<br>14. UNKNOWN<br> |
| **type** | The rough type of this ExitCode | False | False | Enum | 1. USER_SUCCESS<br>2. USER_STOP<br>3. USER_FAILURE<br>4. PLATFORM_FAILURE<br>5. RESOURCE_ALLOCATION_TIMEOUT<br>6. UNKNOWN_FAILURE<br> |
| **stage** | The user process stage just before this ExitCode issued | False | False | Enum | 1. SUBMITTING<br>2. ALLOCATING<br>3. LAUNCHING<br>4. RUNNING<br>5. COMPLETING<br>6. UNKNOWN<br> |
| **behavior** | The rerun behavior of this ExitCode | False | False | Enum | 1. TRANSIENT_NORMAL<br>2. TRANSIENT_CONFLICT<br>3. NON_TRANSIENT<br>4. UNKNOWN<br> |
| **reaction** | The reaction for this ExitCode will be executed by PAI automatically | False | False | Enum | 1. ALWAYS_RETRY<br>2. ALWAYS_BACKOFF_RETRY<br>3. RETRY_TO_MAX<br>4. NEVER_RETRY<br> |
| **reason** | Why this ExitCode is issued | False | False | String | Any |
| **repro** | One specific reproduce steps of this ExitCode | False | False | List\<String\> | Any |
| **solution** | Some optional solutions to resolve this ExitCode if it indicates failure | False | False | List\<String\> | Any |
| **pattern** | The pattern that PAI used to detect this ExitCode | False | False | String | Any, such as USER_EXITCODE=X && USER_LOG_PATTERN=Y \|\| OS_Signal=Z |

## Spec Table
1. You may need to **scroll right side to see full table**.
2. The code **256** is just used to represent all **undefined positive** exitcodes in this spec, and the specific undefined exitcode will always override it to expose to user.
3. The code **-8000** is just used to represent all **undefined negative** exitcodes in this spec, and the specific undefined exitcode will always override it to expose to user.

|code|phrase|issuer|causer|type|stage|behavior|reaction|reason|repro|solution|pattern|
|----|------|------|------|----|-----|--------|--------|------|-----|--------|-------|
| **154** | **CONTAINER_EXIT_CODE_FILE_LOST** | PAI_YARN | PAI_YARN | PLATFORM_FAILURE | COMPLETING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container exitcode file cannot be found by YARN NM, maybe node unexpected shutdown, disk cleaned up or disk failure | 1. Stop YARN NM<br>2. Kill container process<br>3. Delete container exitcode file<br>4. Start YARN NM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **130** | **CONTAINER_KILLED_BY_SIGINT** | PAI_OS | PAI_OS | PLATFORM_FAILURE | RUNNING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by OS Signal: SIGINT | 1. Kill container process by SIGINT<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **132** | **CONTAINER_KILLED_BY_SIGILL** | USER_CONTAINER | USER_CONTAINER | USER_FAILURE | RUNNING | NON_TRANSIENT | NEVER_RETRY | Container killed by OS Signal: SIGILL | 1. User program executes an illegal, malformed, unknown, or privileged machine instruction<br> | 1. Check container log and fix your program bug<br> |  |
| **134** | **CONTAINER_KILLED_BY_SIGABRT** | USER_CONTAINER | UNKNOWN | UNKNOWN_FAILURE | RUNNING | UNKNOWN | RETRY_TO_MAX | Container killed by OS Signal: SIGABRT | 1. User program calls abort() by libc<br> | 1. Check container log and find root cause<br>2. Wait result from next retry<br> |  |
| **135** | **CONTAINER_KILLED_BY_SIGBUS** | USER_CONTAINER | USER_CONTAINER | USER_FAILURE | RUNNING | NON_TRANSIENT | NEVER_RETRY | Container killed by OS Signal: SIGBUS | 1. User program accesses an unaligned memory address<br> | 1. Check container log and fix your program bug<br> |  |
| **136** | **CONTAINER_KILLED_BY_SIGFPE** | USER_CONTAINER | USER_CONTAINER | USER_FAILURE | RUNNING | NON_TRANSIENT | NEVER_RETRY | Container killed by OS Signal: SIGFPE | 1. User program division by zero<br> | 1. Check container log and fix your program bug<br> |  |
| **137** | **CONTAINER_KILLED_BY_SIGKILL** | PAI_OS | PAI_OS | PLATFORM_FAILURE | RUNNING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by OS Signal: SIGKILL | 1. Kill container process by SIGKILL<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **139** | **CONTAINER_KILLED_BY_SIGSEGV** | USER_CONTAINER | USER_CONTAINER | USER_FAILURE | RUNNING | NON_TRANSIENT | NEVER_RETRY | Container killed by OS Signal: SIGSEGV | 1. User program accesses an illegal memory address<br> | 1. Check container log and fix your program bug<br> |  |
| **141** | **CONTAINER_KILLED_BY_SIGPIPE** | USER_CONTAINER | USER_CONTAINER | USER_FAILURE | RUNNING | NON_TRANSIENT | NEVER_RETRY | Container killed by OS Signal: SIGPIPE | 1. User program writes to a pipe without a process connected to the other end<br> | 1. Check container log and fix your program bug<br> |  |
| **143** | **CONTAINER_KILLED_BY_SIGTERM** | PAI_OS | PAI_OS | PLATFORM_FAILURE | RUNNING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by OS Signal: SIGTERM | 1. Kill container process by SIGTERM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **193** | **CONTAINER_DOCKER_RUN_FAILED** | PAI_RUNTIME | PAI_DOCKER | PLATFORM_FAILURE | LAUNCHING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container cannot be launched by docker run | 1. PAI Runtime calls docker run with unknown flag<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **196** | **CONTAINER_OOM_KILLED_BY_DOCKER** | PAI_RUNTIME | USER_CONTAINER | USER_FAILURE | RUNNING | NON_TRANSIENT | NEVER_RETRY | Container killed by docker due to it exceeded the request memory | 1. User program uses more memory than its requested<br> | 1. Increase per task memory request<br>2. Decrease per task memory usage by such as increasing task number<br> |  |
| **198** | **CONTAINER_OOD_KILLED_BY_DISKCLEANER** | PAI_RUNTIME | USER_CONTAINER | USER_FAILURE | RUNNING | NON_TRANSIENT | NEVER_RETRY | Container is killed by disk cleaner due to it used major disk space and all containers disk usage on the node exceeded platform limit | 1. User program uses almost all disk space of the node<br> | 1. Decrease per task disk space usage by such as increasing task number<br> |  |
| **255** | **CONTAINER_RUNTIME_UNKNOWN_FAILURE** | PAI_RUNTIME | UNKNOWN | UNKNOWN_FAILURE | COMPLETING | UNKNOWN | RETRY_TO_MAX | Container failed but the failure cannot be recognized by PAI Runtime | 1. User program directly exits with exitcode 1<br> | 1. Check container log and find root cause<br>2. Wait result from next retry<br> |  |
| **256** | **CONTAINER_RUNTIME_EXIT_ABNORMALLY** | PAI_RUNTIME | PAI_RUNTIME | PLATFORM_FAILURE | UNKNOWN | UNKNOWN | RETRY_TO_MAX | PAI Runtime exit abnormally with undefined exitcode, it may have bugs | 1. PAI Runtime exits with exitcode 1<br> | 1. Contact PAI Dev to fix PAI Runtime bugs<br> |  |
| **0** | **SUCCEEDED** | USER_CONTAINER | USER_CONTAINER | USER_SUCCESS | COMPLETING | UNKNOWN | NEVER_RETRY |  | 1. User program exits with exitcode 0<br> |  |  |
| **-7100** | **CONTAINER_INVALID_EXIT_STATUS** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | LAUNCHING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container exited with invalid exit status, maybe YARN failed to initialize container environment | 1. Disable write permission for YARN NM to access {yarn.nodemanager.local-dirs}<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7101** | **CONTAINER_NOT_AVAILABLE_EXIT_STATUS** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | LAUNCHING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container exited with not available exit status, maybe YARN failed to create container executor process | 1. Disable execute permission for YARN NM to access bash on *nix or winutils.exe on Windows<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7102** | **CONTAINER_NODE_DISKS_FAILED** | PAI_LAUNCHER | PAI_OS | PLATFORM_FAILURE | LAUNCHING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container cannot be launched by YARN due to local bad disk, maybe no disk space left | 1. Set zero disk space for {yarn.nodemanager.local-dirs}<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7103** | **CONTAINER_PORT_CONFLICT** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | LAUNCHING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container cannot be launched by YARN due to local port conflict | 1. After container allocated and before container started, stop the container's YARN NM<br>2. Occupy a container requested port on the container node<br>3. Start the container's YARN NM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7110** | **CONTAINER_ABORTED** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container aborted by YARN | 1. Corrupt the container entry in YARN NM state store<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7111** | **CONTAINER_NODE_LOST** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container lost due to node lost, maybe its YARN NM is down for a long time | 1. Stop the container's YARN NM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7112** | **CONTAINER_EXPIRED** | PAI_LAUNCHER | RESOURCE_ALLOCATION_TIMEOUT | RESOURCE_ALLOCATION_TIMEOUT | ALLOCATING | TRANSIENT_CONFLICT | ALWAYS_BACKOFF_RETRY | Container previously allocated is expired due to it is not launched on YARN NM in time, maybe other containers cannot be allocated in time | 1. Disable virtual cluster bonus token<br>2. Set amGangAllocationTimeoutSec large than yarn.resourcemanager.rm.container-allocation.expiry-interval-ms<br>3. Request more containers in a job than its virtual cluster current available resource<br> | 1. Wait result from next retry<br>2. Decrease task number<br>3. Decrease per task resource request<br>4. Contact Cluster Admin to increase your virtual cluster quota<br> |  |
| **-7113** | **CONTAINER_ABORTED_ON_AM_RESTART** | PAI_LAUNCHER | RESOURCE_ALLOCATION_TIMEOUT | RESOURCE_ALLOCATION_TIMEOUT | ALLOCATING | TRANSIENT_CONFLICT | ALWAYS_BACKOFF_RETRY | Container previously allocated is aborted by YARN RM during Launcher AM restart, maybe other containers cannot be allocated in time | 1. Disable virtual cluster bonus token<br>2. Request more containers in a job than its virtual cluster current available resource<br>3. Kill Launcher AM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7120** | **CONTAINER_PREEMPTED** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container preempted by YARN RM, maybe its virtual cluster overused resource was reclaimed | 1. Enable virtual cluster bonus token<br>2. Request more containers in a job than its virtual cluster current available resource<br>3. Use up all other virtual clusters available resource<br> | 1. Wait result from next retry<br>2. Decrease task number<br>3. Decrease per task resource request<br>4. Contact Cluster Admin to increase your virtual cluster quota<br>5. Contact Cluster Admin to disable your virtual cluster bonus token<br> |  |
| **-7121** | **CONTAINER_RUNTIME_VIRTUAL_MEMORY_EXCEEDED** | PAI_LAUNCHER | PAI_RUNTIME | PLATFORM_FAILURE | UNKNOWN | NON_TRANSIENT | NEVER_RETRY | Container killed by YARN due to its PAI Runtime exceeded the request virtual memory | 1. PAI Runtime uses more virtual memory than its container requested<br> | 1. Increase per task virtual memory request<br>2. Contact PAI Dev to decrease PAI Runtime virtual memory usage<br> |  |
| **-7122** | **CONTAINER_RUNTIME_PHYSICAL_MEMORY_EXCEEDED** | PAI_LAUNCHER | PAI_RUNTIME | PLATFORM_FAILURE | UNKNOWN | NON_TRANSIENT | NEVER_RETRY | Container killed by YARN due to its PAI Runtime exceeded the request physical memory | 1. PAI Runtime uses more physical memory than its container requested<br> | 1. Increase per task physical memory request<br>2. Contact PAI Dev to decrease PAI Runtime physical memory usage<br> |  |
| **-7123** | **CONTAINER_KILLED_BY_AM** | PAI_LAUNCHER | PAI_LAUNCHER | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by Launcher AM, maybe allocated container is rejected | 1. Setup single node cluster<br>2. Submit job with two tasks and antiaffinityAllocation enabled<br>3. Launcher rejects allocated container whose node already allocated another container<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7124** | **CONTAINER_KILLED_BY_RM** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by YARN RM, maybe the container is not managed by YARN RM anymore | 1. Delete the container's app entry in YARN RM state store<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7125** | **CONTAINER_KILLED_ON_APP_COMPLETION** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | COMPLETING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by YARN RM due to its app is already completed | 1. Stop Launcher AM container's YARN NM<br>2. Kill the container's app<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7126** | **CONTAINER_EXTERNAL_UTILIZATION_SPIKED** | PAI_LAUNCHER | PAI_OS | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by YARN due to external utilization spiked | 1. Enable YARN external utilization check<br>2. Start raw process to use up almost all memory on the node<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7150** | **CONTAINER_NM_LAUNCH_FAILED** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | LAUNCHING | TRANSIENT_NORMAL | ALWAYS_RETRY | Container failed to launch on YARN NM | 1. After container allocated and before container started, stop the container's YARN NM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7151** | **CONTAINER_RM_RESYNC_LOST** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container lost after Launcher AM resynced with YARN RM | 1. Stop the container's YARN NM<br>2. Restart YARN RM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7152** | **CONTAINER_RM_RESYNC_EXCEEDED** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | NON_TRANSIENT | NEVER_RETRY | Container exceeded after Launcher AM resynced with YARN RM | 1. Stop the container's YARN NM<br>2. Restart YARN RM<br>3. Wait until AM releases container<br>4. Start the container's YARN NM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7153** | **CONTAINER_MIGRATE_TASK_REQUESTED** | PAI_LAUNCHER | USER_RETRY | USER_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by Launcher due to user MigrateTaskRequest | 1. Send MigrateTaskRequest for the container<br> | 1. Wait result from next retry<br> |  |
| **-7154** | **CONTAINER_AGENT_EXPIRED** | PAI_LAUNCHER | PAI_OS | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Container killed by Launcher due to no Launcher Agent heartbeat is received in time | 1. Enable Launcher Agent<br>2. Bring down the container's node<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7200** | **AM_RM_HEARTBEAT_YARN_EXCEPTION** | PAI_LAUNCHER | USER_SUBMISSION | USER_FAILURE | SUBMITTING | NON_TRANSIENT | NEVER_RETRY | Launcher AM failed to heartbeat with YARN RM due to YarnException, maybe App is non-compliant | 1. Submit a job with invalid node label<br> | 1. Check diagnostics and revise your job config<br> |  |
| **-7201** | **AM_RM_HEARTBEAT_IO_EXCEPTION** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Launcher AM failed to heartbeat with YARN RM due to IOException, maybe YARN RM is down | 1. Stop YARN RM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7202** | **AM_RM_HEARTBEAT_UNKNOWN_EXCEPTION** | PAI_LAUNCHER | UNKNOWN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Launcher AM failed to heartbeat with YARN RM due to unknown Exception | 1. AM sends invalid message to YARN RM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7203** | **AM_RM_HEARTBEAT_SHUTDOWN_REQUESTED** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Launcher AM failed to heartbeat with YARN RM due to ShutdownRequest, maybe AM is not managed by YARN RM anymore | 1. Set small AM expiry time<br>2. Set network partition between AM and YARN RM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7250** | **AM_UNKNOWN_EXCEPTION** | PAI_LAUNCHER | PAI_LAUNCHER | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | Launcher AM failed due to unknown Exception | 1. Set network partition between AM and ZK<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7251** | **AM_NON_TRANSIENT_EXCEPTION** | PAI_LAUNCHER | USER_SUBMISSION | USER_FAILURE | SUBMITTING | NON_TRANSIENT | NEVER_RETRY | Launcher AM failed due to NonTransientException, maybe App is non-compliant | 1. Submit a job with invalid data dir<br> | 1. Check diagnostics and revise your job config<br> |  |
| **-7252** | **AM_GANG_ALLOCATION_TIMEOUT** | PAI_LAUNCHER | RESOURCE_ALLOCATION_TIMEOUT | RESOURCE_ALLOCATION_TIMEOUT | ALLOCATING | TRANSIENT_CONFLICT | ALWAYS_BACKOFF_RETRY | Launcher AM failed due to all the requested resource cannot be satisfied in time | 1. Disable virtual cluster bonus token<br>2. Request more containers in a job than its virtual cluster current available resource<br> | 1. Wait result from next retry<br>2. Decrease task number<br>3. Decrease per task resource request<br>4. Contact Cluster Admin to increase your virtual cluster quota<br> |  |
| **-7300** | **APP_SUBMISSION_YARN_EXCEPTION** | PAI_LAUNCHER | USER_SUBMISSION | USER_FAILURE | SUBMITTING | NON_TRANSIENT | NEVER_RETRY | Failed to submit App to YARN RM due to YarnException, maybe App is non-compliant | 1. Submit a job to invalid virtual cluster<br> | 1. Check diagnostics and revise your job config<br> |  |
| **-7301** | **APP_SUBMISSION_IO_EXCEPTION** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | SUBMITTING | TRANSIENT_NORMAL | ALWAYS_RETRY | Failed to submit App to YARN RM due to IOException, maybe YARN RM is down | 1. Stop YARN RM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7302** | **APP_SUBMISSION_UNKNOWN_EXCEPTION** | PAI_LAUNCHER | UNKNOWN | UNKNOWN_FAILURE | SUBMITTING | UNKNOWN | RETRY_TO_MAX | Failed to submit App to YARN RM due to unknown Exception | 1. Launcher Service sends invalid message to YARN RM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7303** | **APP_KILLED_UNEXPECTEDLY** | PAI_LAUNCHER | UNKNOWN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | App killed unexpectedly and directly through YARN RM | 1. Kill the app directly through YARN RM<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7350** | **APP_RM_RESYNC_LOST** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | UNKNOWN | TRANSIENT_NORMAL | ALWAYS_RETRY | App lost after Launcher Service resynced with YARN RM | 1. Delete the app entry in YARN RM state store<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7351** | **APP_STOP_FRAMEWORK_REQUESTED** | PAI_LAUNCHER | USER_STOP | USER_STOP | UNKNOWN | NON_TRANSIENT | NEVER_RETRY | App stopped by Launcher due to user StopFrameworkRequest | 1. Stop a job<br> |  |  |
| **-7352** | **APP_AM_DIAGNOSTICS_LOST** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | COMPLETING | TRANSIENT_NORMAL | ALWAYS_RETRY | Failed to retrieve AMDiagnostics from YARN, maybe the App is cleaned up in YARN | 1. App is in APPLICATION_RETRIEVING_DIAGNOSTICS state<br>2. Stop Launcher Service<br>3. Delete the app entry in YARN RM state store<br>4. Start Launcher Service<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7353** | **APP_AM_DIAGNOSTICS_DESERIALIZATION_FAILED** | PAI_LAUNCHER | PAI_YARN | PLATFORM_FAILURE | COMPLETING | TRANSIENT_NORMAL | ALWAYS_RETRY | Failed to deserialize AMDiagnostics from YARN, maybe it is corrupted or Launcher AM unexpectedly crashed frequently without generating AMDiagnostics | 1. Set yarn.app.attempt.diagnostics.limit.kc to 1B<br> | 1. Wait result from next retry<br>2. Contact Cluster Admin<br> |  |
| **-7400** | **TASK_STOPPED_ON_APP_COMPLETION** | PAI_LAUNCHER | USER_STOP | USER_STOP | UNKNOWN | NON_TRANSIENT | NEVER_RETRY | Task stopped by Launcher due to its app is already completed | 1. Stop a job with long running container<br> |  |  |
| **-8000** | **CONTAINER_UNKNOWN_YARN_EXIT_STATUS** | PAI_YARN | UNKNOWN | UNKNOWN_FAILURE | UNKNOWN | UNKNOWN | RETRY_TO_MAX | Container exited with unknown exitcode which is issued from YARN | 1. Change YARN code to make it return container exitcode -886<br> | 1. Contact PAI Dev to recognize this exitcode<br> |  |

