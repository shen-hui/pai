protocolVersion: 2
name: tensorflow_serving_mnist
type: job
version: 1.0
contributor: OpenPAI
description: |
  # Serving a TensorFlow MNIST Digit Recognition Model
  This example shows you how to use TensorFlow Serving components to export a trained TensorFlow model
  and use the standard tensorflow_model_server to serve it on OpenPAI.
  This example uses the simple Softmax Regression model introduced in the TensorFlow tutorial for handwritten image (MNIST data) classification.
  Reference https://www.tensorflow.org/tfx/serving/serving_basic.

parameters:
  modelPath: /tmp/mnist_model

prerequisites:
  - protocolVersion: 2
    name: tf_serving_example
    type: dockerimage
    version: 1.0-r1.4
    contributor : OpenPAI
    description: |
      This is an [example TensorFlow Serving Docker image on OpenPAI](https://github.com/Microsoft/pai/tree/master/examples/serving).
    uri : openpai/pai.example.tensorflow-serving

taskRoles:
  worker:
    instances: 1
    dockerImage: tf_serving_example
    resourcePerInstance:
      cpu: 4
      memoryMB: 8192
      gpu: 1
      ports:
        model_server: 1
    commands:
      - bazel-bin/tensorflow_serving/example/mnist_saved_model <% $parameters.modelPath %>
      - tensorflow_model_server --port=$PAI_CONTAINER_HOST_model_server_PORT_LIST --model_name=mnist --model_base_path=<% $parameters.modelPath %>
